# ğŸš€ TOPOLOGY KNOWLEDGE PLATFORM - UNIFIED STARTUP

## Overview

This project provides a unified approach to run the complete Topology Knowledge Platform with just **2 simple commands**:

```bash
# Quick Start - Interactive Menu
./start.sh

# Or directly:
./start_server_mode.sh    # For development/direct mode
./start_docker_mode.sh    # For containerized mode
```

## Project Structure

```
TOPOLOGYKNOWLEDGE/
â”œâ”€â”€ corebackend/          # Core Backend (formerly QwenRoute)
â”‚   â”œâ”€â”€ qwenroute/
â”‚   â””â”€â”€ implementation/
â”œâ”€â”€ openwebuibase/        # OpenWebUI with integrated features
â”‚   â”œâ”€â”€ knowledge-fusion/ # IBM Knowledge Fusion Platform
â”‚   â”‚   â”œâ”€â”€ functions/    # OpenWebUI Functions
â”‚   â”‚   â”œâ”€â”€ enhanced_backend/
â”‚   â”‚   â””â”€â”€ integration/
â”‚   â””â”€â”€ backend/
â”œâ”€â”€ start.sh             # ğŸ¯ MAIN LAUNCHER (Interactive)
â”œâ”€â”€ start_server_mode.sh # ğŸ–¥ï¸  SERVER MODE
â””â”€â”€ start_docker_mode.sh # ğŸ³ DOCKER MODE
```

## ğŸ¯ Quick Start Guide

### Option 1: Interactive Launcher (Recommended)
```bash
./start.sh
```
This provides a menu to choose:
- ğŸ–¥ï¸  Server Mode
- ğŸ³ Docker Mode  
- ğŸ” Status Check
- ğŸ›‘ Stop All

### Option 2: Direct Mode Selection

**Server Mode** (Development/Local):
```bash
./start_server_mode.sh
```

**Docker Mode** (Production/Containerized):
```bash
./start_docker_mode.sh
```

## ğŸ–¥ï¸ Server Mode Details

**What it does:**
1. âœ… Verifies Python 3.11 virtual environment
2. âœ… Starts/verifies local Ollama
3. âœ… Starts Core Backend (Port 8001)
4. âœ… Starts Knowledge Fusion Backend (Port 8002)  
5. âœ… Starts OpenWebUI with integrated functions (Port 3000)
6. âœ… Runs health checks on all services
7. âœ… Provides monitoring and status updates

**Requirements:**
- Python 3.11+ virtual environment set up
- Ollama installed locally
- All dependencies installed

**Access Points:**
- ğŸŒ OpenWebUI: http://localhost:3000
- ğŸ”§ Core Backend API: http://localhost:8001
- ğŸ§  Knowledge Fusion: http://localhost:8002
- ğŸ¤– Ollama API: http://localhost:11434

## ğŸ³ Docker Mode Details

**What it does:**
1. âœ… Verifies Docker and docker-compose
2. âœ… Creates optimized Docker Compose configuration
3. âœ… Builds all containers with Knowledge Fusion integration
4. âœ… Starts/verifies local Ollama (runs outside Docker)
5. âœ… Starts all services in containers
6. âœ… Runs health checks and monitoring

**Requirements:**
- Docker installed and running
- docker-compose available
- Ollama installed locally

**Features:**
- Isolated container environment
- Automatic service dependencies
- Health checks and restart policies
- Easy scaling and management

## ğŸ§  Knowledge Fusion Integration

The IBM Knowledge Fusion is **automatically integrated** in both modes:

### Server Mode Integration:
- Function file: `openwebuibase/knowledge-fusion/functions/ibm_knowledge_fusion.py`
- Backend runs on port 8002
- Automatically available in OpenWebUI Functions

### Docker Mode Integration:
- Knowledge Fusion built into OpenWebUI container
- Function automatically mounted and available
- Backend runs in dedicated container

### To Enable in OpenWebUI:
1. Access http://localhost:3000
2. Go to **Settings** â†’ **Functions**
3. Find **"IBM Knowledge Fusion"**
4. Enable the function
5. Start using enhanced AI capabilities!

## ğŸ” Monitoring and Management

### Health Checks
Both scripts provide continuous monitoring:
- Service availability checks every 30 seconds
- Automatic failure detection
- Status reporting

### Logs and Debugging

**Server Mode:**
```bash
# View real-time logs
tail -f demo.log

# Check specific service
curl http://localhost:8001/health
curl http://localhost:8002/health
curl http://localhost:3000
```

**Docker Mode:**
```bash
# View all logs
docker-compose -f docker-compose.knowledge-fusion.yml logs -f

# View specific service logs
docker-compose -f docker-compose.knowledge-fusion.yml logs -f openwebui
docker-compose -f docker-compose.knowledge-fusion.yml logs -f core-backend
docker-compose -f docker-compose.knowledge-fusion.yml logs -f knowledge-fusion

# Check container status
docker-compose -f docker-compose.knowledge-fusion.yml ps
```

### Stopping Services

**Using the launcher:**
```bash
./start.sh  # Choose option 4 to stop all
```

**Manual stopping:**
```bash
# Server mode: Ctrl+C in the terminal
# Docker mode: 
./start_docker_mode.sh --stop
# or
docker-compose -f docker-compose.knowledge-fusion.yml down
```

## ğŸ› ï¸ Troubleshooting

### Common Issues:

1. **Port conflicts:**
   - Check what's using ports: `lsof -i :3000,8001,8002,11434`
   - Stop conflicting services

2. **Ollama not running:**
   - Install: https://ollama.ai
   - Start: `ollama serve`
   - Verify: `curl http://localhost:11434`

3. **Docker issues:**
   - Ensure Docker is running: `docker info`
   - Check disk space: `docker system df`
   - Clean up: `docker system prune`

4. **Python environment issues:**
   - Verify virtual environment: `source openwebui_venv/bin/activate`
   - Check Python version: `python --version` (should be 3.11+)

### Status Checking:
```bash
# Quick status check
./start.sh  # Choose option 3

# Manual checks
curl -s http://localhost:3000 && echo "OpenWebUI: OK"
curl -s http://localhost:8001/health && echo "Core Backend: OK"  
curl -s http://localhost:8002/health && echo "Knowledge Fusion: OK"
curl -s http://localhost:11434 && echo "Ollama: OK"
```

## ğŸ“š Documentation

- **API Documentation:** `docs/QWENROUTE_API_DOCUMENTATION.md`
- **Setup Guide:** `OPENWEBUI_SUCCESS.md`
- **Docker Guide:** `DOCKER_SUCCESS_GUIDE.md`
- **Knowledge Fusion:** `openwebuibase/knowledge-fusion/README.md`

## ğŸ¯ Next Steps

1. **First Time Setup:**
   ```bash
   ./start.sh  # Choose your preferred mode
   ```

2. **Access OpenWebUI:**
   - Visit: http://localhost:3000
   - Create admin account (first time)
   - Enable IBM Knowledge Fusion function

3. **Start Using:**
   - Ask complex questions
   - Upload documents for analysis
   - Experience enhanced AI capabilities

## ğŸ”„ Migration from Old Scripts

If you have old startup scripts, you can safely remove them:
- `run_openwebui.sh` â†’ Use `./start_server_mode.sh`
- `start_openwebui.sh` â†’ Use `./start_server_mode.sh`  
- Multiple docker scripts â†’ Use `./start_docker_mode.sh`

The new unified scripts handle everything the old ones did, plus more!

---

**ğŸ‰ Enjoy your unified Topology Knowledge Platform!**
